import uuid
import json
import time
from qdrant_client import QdrantClient
from qdrant_client.models import VectorParams, Distance, PointStruct
from protonx import ProtonX 
import os

from config import QDRANT_URL, QDRANT_API_KEY, COLLECTION_NAME, PROTONX_API_KEY
# ===================== CONFIG =====================
qdrant = QdrantClient(url=QDRANT_URL, api_key=QDRANT_API_KEY)

# ===================== STEP 1. ƒê·ªçc file JSON ch·ª©a th√¥ng tin b√°c sƒ© =====================
def read_doctors_json(file_path):
    with open(file_path, 'r', encoding='utf-8') as f:
        doctors = json.load(f)
    print(f"üìñ ƒê√£ ƒë·ªçc {len(doctors)} b√°c sƒ© t·ª´ file JSON")
    return doctors

# ===================== STEP 2. Format th√¥ng tin b√°c sƒ© =====================
def format_doctor_info(doctor):
    """Format th√¥ng tin b√°c sƒ© theo d·∫°ng: Chuy√™n m√¥n, N∆°i l√†m vi·ªác, Gi·ªõi thi·ªáu"""
    chuyen_mon = ", ".join(doctor.get("chuyen_mon", [])) if doctor.get("chuyen_mon") else "Kh√¥ng c√≥ th√¥ng tin"
    noi_lam_viec = doctor.get("noi_lam_viec", "Kh√¥ng c√≥ th√¥ng tin")
    gioi_thieu = doctor.get("gioi_thieu", "Kh√¥ng c√≥ th√¥ng tin")
    
    formatted_text = f"""Chuy√™n m√¥n: {chuyen_mon}

N∆°i l√†m vi·ªác: {noi_lam_viec}

Gi·ªõi thi·ªáu: {gioi_thieu}"""
    
    return formatted_text

# ===================== STEP 3. T·∫°o batch embedding =====================
protonx_client = ProtonX(api_key=PROTONX_API_KEY)

def get_batch_embeddings(texts, max_retries=5):
    """
    T·∫°o embedding cho nhi·ªÅu text c√πng l√∫c (batch)
    
    Args:
        texts: List c√°c text c·∫ßn t·∫°o embedding
        max_retries: S·ªë l·∫ßn th·ª≠ l·∫°i
    
    Returns:
        List c√°c embedding vectors
    """
    for attempt in range(max_retries):
        try:
            # G·ªçi API v·ªõi batch texts
            response = protonx_client.embeddings.create(texts)
            
            # ProtonX tr·∫£ v·ªÅ dict v·ªõi nhi·ªÅu embeddings
            if isinstance(response, dict):
                embeddings = [item["embedding"] for item in response["data"]]
                return embeddings
            else:
                embeddings = [item.embedding for item in response.data]
                return embeddings
                
        except Exception as e:
            error_str = str(e)
            # Ki·ªÉm tra n·∫øu l√† l·ªói rate limit (429 ho·∫∑c TOKEN_LIMIT_EXCEEDED)
            if "429" in error_str or "rate limit" in error_str.lower() or "per-minute" in error_str.lower():
                if attempt < max_retries - 1:
                    print(f"‚ö†Ô∏è ƒê·∫°t rate limit! Ch·ªù 60s...")
                    time.sleep(60)
                else:
                    print(f"‚ùå V·∫´n b·ªã rate limit sau {max_retries} l·∫ßn th·ª≠")
                    raise
            else:
                # L·ªói kh√°c, th·ª≠ l·∫°i ngay
                if attempt < max_retries - 1:
                    print(f"‚ö†Ô∏è L·ªói (attempt {attempt + 1}/{max_retries}): {error_str[:150]}")
                    print(f"‚è≥ Th·ª≠ l·∫°i ngay...")
                else:
                    print(f"‚ùå Kh√¥ng th·ªÉ t·∫°o batch embedding sau {max_retries} l·∫ßn th·ª≠")
                    raise
    return None

# ===================== STEP 4. X√≥a v√† t·∫°o l·∫°i collection Qdrant =====================
def recreate_collection():
    """X√≥a collection c≈© (n·∫øu c√≥) v√† t·∫°o collection m·ªõi"""
    collections = [c.name for c in qdrant.get_collections().collections]
    
    # X√≥a collection c≈© n·∫øu t·ªìn t·∫°i
    if COLLECTION_NAME in collections:
        qdrant.delete_collection(collection_name=COLLECTION_NAME)
        print(f"üóëÔ∏è ƒê√£ x√≥a collection c≈© '{COLLECTION_NAME}'")
    
    # T·∫°o collection m·ªõi v·ªõi named vector
    qdrant.create_collection(
        collection_name=COLLECTION_NAME,
        vectors_config={
            "default": VectorParams(size=768, distance=Distance.COSINE)
        }
    )
    print(f"‚úÖ ƒê√£ t·∫°o collection m·ªõi '{COLLECTION_NAME}'")

# ===================== STEP 5. T·∫°o embeddings v√† l∆∞u v√†o file local =====================
def create_and_save_embeddings(doctors, batch_size=100, output_file="doctor_embeddings.json"):
    """
    T·∫°o embeddings cho t·∫•t c·∫£ b√°c sƒ© theo batch v√† l∆∞u v√†o file local
    
    Args:
        doctors: Danh s√°ch b√°c sƒ©
        batch_size: S·ªë l∆∞·ª£ng b√°c sƒ© m·ªói batch (m·ªói request API)
        output_file: T√™n file ƒë·ªÉ l∆∞u embeddings
    
    Returns:
        List c√°c doctor data v·ªõi embeddings
    """
    total = len(doctors)
    all_doctor_data = []
    request_count = 0
    start_time = time.time()
    
    print(f"üìä T·ªïng s·ªë b√°c sƒ©: {total}")
    print(f"üì¶ Batch size: {batch_size} b√°c sƒ©/request")
    print(f"‚ö° G·ªçi API li√™n t·ª•c (ch·ªâ ch·ªù 60s khi g·∫∑p rate limit)")
    print("-" * 60)
    
    # X·ª≠ l√Ω theo batch
    for batch_idx in range(0, total, batch_size):
        batch_end = min(batch_idx + batch_size, total)
        batch_doctors = doctors[batch_idx:batch_end]
        batch_num = (batch_idx // batch_size) + 1
        
        print(f"\nüîÑ ƒêang x·ª≠ l√Ω batch {batch_num}: B√°c sƒ© {batch_idx + 1} ƒë·∫øn {batch_end}...")
        
        try:
            # Format text cho t·∫•t c·∫£ b√°c sƒ© trong batch
            batch_texts = [format_doctor_info(doctor) for doctor in batch_doctors]
            
            # T·∫°o embeddings cho c·∫£ batch (1 request API duy nh·∫•t)
            print(f"üì° G·ªçi API ƒë·ªÉ t·∫°o {len(batch_texts)} embeddings...")
            batch_embeddings = get_batch_embeddings(batch_texts)
            request_count += 1
            
            if batch_embeddings is None:
                print(f"‚ùå Kh√¥ng th·ªÉ t·∫°o embeddings cho batch {batch_num}, b·ªè qua...")
                continue
            
            # K·∫øt h·ª£p data v·ªõi embeddings
            for idx, (doctor, text, embedding) in enumerate(zip(batch_doctors, batch_texts, batch_embeddings)):
                doctor_data = {
                    "doctor_id": batch_idx + idx,
                    "ten_bac_si": doctor.get("ten_bac_si", ""),
                    "chuyen_mon": doctor.get("chuyen_mon", []),
                    "noi_lam_viec": doctor.get("noi_lam_viec", ""),
                    "gioi_thieu": doctor.get("gioi_thieu", ""),
                    "url": doctor.get("url", ""),
                    "text": text,
                    "embedding": embedding
                }
                all_doctor_data.append(doctor_data)
            
            print(f"‚úÖ ƒê√£ x·ª≠ l√Ω batch {batch_num} - T·ªïng: {batch_end}/{total} b√°c sƒ© ({(batch_end / total * 100):.1f}%)")
                
        except Exception as e:
            error_msg = str(e)[:200]
            print(f"\n‚ùå L·ªói khi x·ª≠ l√Ω batch {batch_num}: {error_msg}")
            print("‚è© B·ªè qua batch n√†y v√† ti·∫øp t·ª•c...\n")
            continue
    
    # L∆∞u v√†o file JSON
    print(f"\nüíæ ƒêang l∆∞u {len(all_doctor_data)} b√°c sƒ© v√†o file '{output_file}'...")
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(all_doctor_data, f, ensure_ascii=False, indent=2)
    
    elapsed_time = time.time() - start_time
    print(f"‚úÖ ƒê√£ l∆∞u embeddings v√†o file!")
    print(f"‚è±Ô∏è  T·ªïng th·ªùi gian: {elapsed_time/60:.1f} ph√∫t")
    print(f"üìä T·ªïng s·ªë request API: {request_count}")
    
    return all_doctor_data

# ===================== STEP 6. Upload embeddings t·ª´ file l√™n Qdrant =====================
def upload_embeddings_to_qdrant(doctor_data_list, batch_size=100):
    """
    Upload embeddings t·ª´ file local l√™n Qdrant
    
    Args:
        doctor_data_list: List c√°c doctor data v·ªõi embeddings
        batch_size: S·ªë l∆∞·ª£ng points m·ªói l·∫ßn upload l√™n Qdrant
    """
    total = len(doctor_data_list)
    print(f"\nüì§ B·∫Øt ƒë·∫ßu upload {total} b√°c sƒ© l√™n Qdrant...")
    print(f"üì¶ Upload batch size: {batch_size} points/batch")
    print("-" * 60)
    
    # Upload theo batch
    for batch_idx in range(0, total, batch_size):
        batch_end = min(batch_idx + batch_size, total)
        batch_data = doctor_data_list[batch_idx:batch_end]
        batch_num = (batch_idx // batch_size) + 1
        
        # T·∫°o points cho Qdrant
        points = []
        for data in batch_data:
            point = PointStruct(
                id=str(uuid.uuid4()),
                vector={"default": data["embedding"]},
                payload={
                    "text": data["text"],
                    "ten_bac_si": data["ten_bac_si"],
                    "chuyen_mon": data["chuyen_mon"],
                    "noi_lam_viec": data["noi_lam_viec"],
                    "gioi_thieu": data["gioi_thieu"],
                    "url": data["url"],
                    "doctor_id": data["doctor_id"]
                }
            )
            points.append(point)
        
        # Upload batch
        print(f"üì§ Uploading batch {batch_num} ({len(points)} b√°c sƒ©)...")
        qdrant.upsert(collection_name=COLLECTION_NAME, points=points)
        print(f"‚úÖ ƒê√£ upload batch {batch_num} - T·ªïng: {batch_end}/{total} b√°c sƒ© ({(batch_end / total * 100):.1f}%)")
    
    print(f"\n‚úÖ Ho√†n th√†nh upload l√™n Qdrant!")

# ===================== MAIN =====================
if __name__ == "__main__":
    # ƒê∆∞·ªùng d·∫´n file JSON ch·ª©a th√¥ng tin b√°c sƒ©

    json_file_path = "/Users/apple/VITA /Doctor_vinmec/crawl_data/vinmec_doctors_unique.json"
    embeddings_file = "/Users/apple/VITA /Doctor_vinmec/Database/doctor_embeddings.json"
    
    print("=" * 60)
    print("üè• B·∫ÆT ƒê·∫¶U UPLOAD TH√îNG TIN B√ÅC Sƒ® L√äN QDRANT")
    print("=" * 60)
    
    # B∆∞·ªõc 1: ƒê·ªçc file JSON
    print("\nüìñ B∆∞·ªõc 1: ƒê·ªçc file JSON...")
    doctors = read_doctors_json(json_file_path)
    
    # B∆∞·ªõc 2: T·∫°o embeddings v√† l∆∞u v√†o file local
    print("\nü§ñ B∆∞·ªõc 2: T·∫°o embeddings cho t·∫•t c·∫£ b√°c sƒ© (batch processing)...")
    doctor_data_list = create_and_save_embeddings(
        doctors, 
        batch_size=5,  # 5 b√°c sƒ© m·ªói request API (tr√°nh v∆∞·ª£t qu√° 4096 tokens)
        output_file=embeddings_file
    )
    
    # B∆∞·ªõc 3: X√≥a v√† t·∫°o l·∫°i collection Qdrant
    print("\nüóëÔ∏è B∆∞·ªõc 3: X√≥a collection c≈© v√† t·∫°o m·ªõi...")
    recreate_collection()
    
    # B∆∞·ªõc 4: Upload embeddings l√™n Qdrant
    print("\nüöÄ B∆∞·ªõc 4: Upload embeddings l√™n Qdrant...")
    upload_embeddings_to_qdrant(
        doctor_data_list,
        batch_size=100  # 100 points m·ªói l·∫ßn upload
    )
    
    print("\n" + "=" * 60)
    print("üéâ HO√ÄN TH√ÄNH! ƒê√£ upload th√¥ng tin b√°c sƒ© l√™n Qdrant Cloud.")
    print("=" * 60)
    print(f"üíæ File embeddings ƒë√£ l∆∞u t·∫°i: {embeddings_file}")
    
    # Test t√¨m ki·∫øm
    print("\nüîç Test t√¨m ki·∫øm...")
    query = "B√°c sƒ© chuy√™n khoa tim m·∫°ch"
    print(f"üì° T·∫°o embedding cho query...")
    query_emb = get_batch_embeddings([query])[0]
    
    hits = qdrant.search(
        collection_name=COLLECTION_NAME,
        query_vector=("default", query_emb),
        limit=3
    )
    
    print(f"\nK·∫øt qu·∫£ t√¨m ki·∫øm cho: '{query}'")
    print("-" * 60)
    for i, h in enumerate(hits, 1):
        print(f"\n{i}. Score: {h.score:.3f}")
        print(f"T√™n b√°c sƒ©: {h.payload.get('ten_bac_si', 'N/A')}")
        print(f"Chuy√™n m√¥n: {', '.join(h.payload.get('chuyen_mon', []))}")
        print(f"N∆°i l√†m vi·ªác: {h.payload.get('noi_lam_viec', 'N/A')}")
        print("-" * 60)
