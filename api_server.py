import os
import logging
from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
from typing import Optional, List, Dict
import uvicorn
from agent_with_memory import MemoryAgent

# Setup logger
logger = logging.getLogger(__name__)

# Import telemetry configuration (must be before other imports that use OpenTelemetry)
try:
    from telemetry_config import setup_telemetry
    from opentelemetry import trace, metrics
    from opentelemetry.instrumentation.fastapi import FastAPIInstrumentor
    from opentelemetry.trace import Status, StatusCode
    
    tracer = trace.get_tracer("api_server")
    meter = metrics.get_meter("api_server")
    TELEMETRY_ENABLED = True
    logger.info("‚úÖ OpenTelemetry enabled for API server")
except ImportError as e:
    TELEMETRY_ENABLED = False
    tracer = None
    meter = None
    logger.warning(f"‚ö†Ô∏è OpenTelemetry not available: {e}")

# ============================================================================
# Configuration
# ============================================================================

from config import OPENAI_API_KEY
LONGTERM_FILE = "longterm.txt"

# ============================================================================
# FastAPI App
# ============================================================================

app = FastAPI(
    title="Memory Agent API",
    description="API cho Memory Agent v·ªõi long-term memory v√† doctor retrieval",
    version="1.0.0"
)

# Instrument FastAPI with OpenTelemetry
if TELEMETRY_ENABLED:
    FastAPIInstrumentor.instrument_app(app)
    logger.info("‚úÖ FastAPI instrumented with OpenTelemetry")

# CORS middleware
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# ============================================================================
# Global Agent Instance & Tool Call History
# ============================================================================

agent: Optional[MemoryAgent] = None
tool_call_history: List[Dict] = []

def get_agent() -> MemoryAgent:
    """L·∫•y ho·∫∑c kh·ªüi t·∫°o agent instance"""
    global agent
    if agent is None:
        agent = MemoryAgent(
            openai_api_key=OPENAI_API_KEY,
            model_name="gpt-4o-mini",
            buffer_size=10,
            longterm_file=LONGTERM_FILE
        )
    return agent

# ============================================================================
# Request/Response Models
# ============================================================================

class ChatRequest(BaseModel):
    message: str
    session_id: Optional[str] = "default"

class ToolCall(BaseModel):
    tool_name: str
    tool_input: Dict
    tool_output: str

class ChatResponse(BaseModel):
    response: str
    session_id: str
    tools_used: Optional[List[ToolCall]] = []

class MemoryResponse(BaseModel):
    content: str

class BufferMemoryResponse(BaseModel):
    messages: List[Dict[str, str]]

class StatusResponse(BaseModel):
    status: str
    message: str

# ============================================================================
# API Endpoints
# ============================================================================

@app.get("/")
async def root():
    """Health check endpoint"""
    return {
        "status": "running",
        "service": "Memory Agent API",
        "version": "1.0.0"
    }

@app.post("/chat", response_model=ChatResponse)
async def chat(request: ChatRequest):
    """
    Chat v·ªõi agent (c√≥ auto-priming)
    
    Args:
        request: ChatRequest v·ªõi message v√† session_id
        
    Returns:
        ChatResponse v·ªõi response t·ª´ agent v√† danh s√°ch tools ƒë√£ s·ª≠ d·ª•ng
    """
    try:
        global tool_call_history
        agent_instance = get_agent()
        
        # S·ª≠ d·ª•ng agent.chat() thay v√¨ agent_executor.invoke() ƒë·ªÉ c√≥ priming
        with tracer.start_as_current_span("chat_with_agent") as chat_span:
            response_text = agent_instance.chat(request.message, auto_prime=True)
            chat_span.set_attribute("chat_with_agent.value", response_text)
        
        # Note: Khi d√πng agent.chat(), kh√¥ng c√≥ intermediate_steps
        # N·∫øu c·∫ßn track tools, ph·∫£i modify agent.chat() ƒë·ªÉ return c·∫£ intermediate_steps
        
        return ChatResponse(
            response=response_text,
            session_id=request.session_id,
            tools_used=[]  # T·∫°m th·ªùi empty, c√≥ th·ªÉ enhance sau
        )
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"L·ªói khi chat: {str(e)}")

@app.get("/memory/longterm", response_model=MemoryResponse)
async def get_longterm_memory():
    """
    L·∫•y n·ªôi dung long-term memory
    
    Returns:
        MemoryResponse v·ªõi n·ªôi dung long-term memory
    """
    try:
        agent_instance = get_agent()
        content = agent_instance.view_longterm_memory()
        
        return MemoryResponse(content=content)
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"L·ªói khi l·∫•y long-term memory: {str(e)}")

@app.get("/memory/buffer", response_model=BufferMemoryResponse)
async def get_buffer_memory():
    """
    L·∫•y n·ªôi dung buffer memory
    
    Returns:
        BufferMemoryResponse v·ªõi danh s√°ch messages
    """
    try:
        agent_instance = get_agent()
        messages = agent_instance.view_buffer_memory()
        
        formatted_messages = []
        for msg in messages:
            role = "user" if msg.type == "human" else "assistant"
            formatted_messages.append({
                "role": role,
                "content": msg.content
            })
        
        return BufferMemoryResponse(messages=formatted_messages)
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"L·ªói khi l·∫•y buffer memory: {str(e)}")

@app.delete("/memory/longterm", response_model=StatusResponse)
async def clear_longterm_memory():
    """
    X√≥a long-term memory
    
    Returns:
        StatusResponse v·ªõi tr·∫°ng th√°i
    """
    try:
        agent_instance = get_agent()
        agent_instance.clear_longterm_memory()
        
        return StatusResponse(
            status="success",
            message="ƒê√£ x√≥a long-term memory"
        )
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"L·ªói khi x√≥a long-term memory: {str(e)}")

@app.delete("/memory/buffer", response_model=StatusResponse)
async def clear_buffer_memory():
    """
    X√≥a buffer memory
    
    Returns:
        StatusResponse v·ªõi tr·∫°ng th√°i
    """
    try:
        agent_instance = get_agent()
        agent_instance.clear_buffer_memory()
        
        return StatusResponse(
            status="success",
            message="ƒê√£ x√≥a buffer memory"
        )
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"L·ªói khi x√≥a buffer memory: {str(e)}")

@app.get("/tools/history")
async def get_tool_history():
    """
    L·∫•y l·ªãch s·ª≠ tool calls
    
    Returns:
        Danh s√°ch c√°c tool calls ƒë√£ th·ª±c hi·ªán
    """
    global tool_call_history
    return {
        "total_calls": len(tool_call_history),
        "history": tool_call_history
    }

@app.delete("/tools/history")
async def clear_tool_history():
    """
    X√≥a l·ªãch s·ª≠ tool calls
    
    Returns:
        StatusResponse
    """
    global tool_call_history
    tool_call_history = []
    return StatusResponse(
        status="success",
        message="ƒê√£ x√≥a l·ªãch s·ª≠ tool calls"
    )

@app.get("/health")
async def health_check():
    """Health check endpoint"""
    try:
        agent_instance = get_agent()
        return {
            "status": "healthy",
            "agent_initialized": agent_instance is not None,
            "longterm_file": LONGTERM_FILE,
            "longterm_exists": os.path.exists(LONGTERM_FILE),
            "total_tool_calls": len(tool_call_history),
            "is_primed": agent_instance.is_primed if agent_instance else False,
            "messages_since_prime": agent_instance.message_count_since_prime if agent_instance else 0,
            "buffer_size": agent_instance.buffer_size if agent_instance else 0
        }
    except Exception as e:
        return {
            "status": "unhealthy",
            "error": str(e)
        }

@app.get("/priming/status")
async def get_priming_status():
    """
    L·∫•y tr·∫°ng th√°i priming c·ªßa agent
    
    Returns:
        Th√¥ng tin v·ªÅ priming status
    """
    try:
        agent_instance = get_agent()
        return {
            "is_primed": agent_instance.is_primed,
            "message_count_since_prime": agent_instance.message_count_since_prime,
            "buffer_size": agent_instance.buffer_size,
            "should_reprime": agent_instance._should_reprime(),
            "messages_until_reprime": max(0, agent_instance.buffer_size - agent_instance.message_count_since_prime)
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"L·ªói khi l·∫•y priming status: {str(e)}")

# ============================================================================
# Main
# ============================================================================

if __name__ == "__main__":
    print("üöÄ Starting Memory Agent API Server...")
    print("üìç Server will be available at: http://localhost:8000")
    print("üìö API docs available at: http://localhost:8000/docs")
    
    uvicorn.run(
        "api_server:app",
        host="0.0.0.0",
        port=8000,
        reload=True,
        log_level="info"
    )

